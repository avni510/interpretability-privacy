{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81700b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import train_network as train_network\n",
    "import utils as utils\n",
    "import adult_network as adult_network\n",
    "import dataloader as dataloader\n",
    "import copy\n",
    "import attack as attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e9182d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSAMPLE_SIZE = 2500\n",
    "SETS = 4\n",
    "BATCH_SIZE = 8\n",
    "NUM_ITER = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c261bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.dirname(os.getcwd())\n",
    "EXPERIMENT_DIR = ROOT_DIR + \"/experiments/adult\"\n",
    "MODEL_PATH = ROOT_DIR + \"/saved_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "928050dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(in_features, num=4):\n",
    "    layer_sizes = [20, 20, 20, 20, 2]\n",
    "    models = []\n",
    "    for i in range(0, 4):\n",
    "        model = adult_network.AdultNetwork(in_features, layer_sizes)\n",
    "        models.append(model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6d65571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(models, dataloaders, model_infos, log_tensorboard=False):\n",
    "    for idx, model in enumerate(models):\n",
    "        train_loader = dataloaders[idx][0]\n",
    "        info = model_infos[idx]\n",
    "        model, train_losses, train_accuracies = train_network.train(\n",
    "                model,\n",
    "                train_loader,\n",
    "                idx,\n",
    "                SUBSAMPLE_SIZE,\n",
    "                log_tensorboard\n",
    "                )\n",
    "        info['training_losses'] = train_losses\n",
    "        info['training_accuracies'] = train_accuracies\n",
    "        info['model_params'] = model.state_dict()\n",
    "\n",
    "    return model_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b53fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models(models, dataloaders, model_infos):\n",
    "    losses_accuracies = []\n",
    "    for idx, model in enumerate(models):\n",
    "        test_loader = dataloaders[idx][1]\n",
    "        info = model_infos[idx]\n",
    "        test_loss, test_accuracy = train_network.test(\n",
    "                model,\n",
    "                info['model_params'],\n",
    "                idx,\n",
    "                test_loader,\n",
    "                SUBSAMPLE_SIZE\n",
    "                )\n",
    "        info['test_loss'] = test_loss\n",
    "        info['test_accuracy'] = test_accuracy\n",
    "\n",
    "    return model_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3b66ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_attributions(models, dataloaders, model_infos):\n",
    "    model_attributions = []\n",
    "\n",
    "    for idx, (model, dataloader) in enumerate(list(zip(models, dataloaders))):\n",
    "        train_loader = dataloader[0]\n",
    "        test_loader = dataloader[1]\n",
    "        info = model_infos[idx]\n",
    "\n",
    "        info['train_attributions'] =  train_network.get_attributions(\n",
    "                model,\n",
    "                info['model_params'],\n",
    "                idx,\n",
    "                train_loader\n",
    "                )\n",
    "        info['test_attributions'] = train_network.get_attributions(\n",
    "                model,\n",
    "                info['model_params'],\n",
    "                idx,\n",
    "                test_loader\n",
    "                )\n",
    "\n",
    "    return model_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4268d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_train_test_sets(subsets, info, model_infos):\n",
    "    for i, info in enumerate(model_infos):\n",
    "        train = subsets[i]\n",
    "        test = subsets[i + 1] if i + 1 < len(subsets) else subsets[0]\n",
    "        train_normalize, test_normalize = dataloader.normalize(train, test)\n",
    "\n",
    "        info['train_set'] = train_normalize\n",
    "        info['test_set'] = test_normalize\n",
    "\n",
    "    return model_infos\n",
    "\n",
    "def init_model_infos(info, model_infos, sets):\n",
    "    for i in range(0, sets):\n",
    "        m_info = copy.deepcopy(info)\n",
    "        m_info['model_name'] = 'model_' + str(i)\n",
    "\n",
    "        model_infos.append(m_info)\n",
    "    return model_infos\n",
    "\n",
    "def save_model_infos(model_infos, new_dir_name, i):\n",
    "    for info in model_infos:\n",
    "        model_name = info['model_name']\n",
    "        np.save(EXPERIMENT_DIR + new_dir_name + '/' + model_name, np.array(info))\n",
    "\n",
    "def create_new_dir(name):\n",
    "    if not os.path.exists(EXPERIMENT_DIR + name):\n",
    "        os.mkdir(EXPERIMENT_DIR + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91649a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(retrain=False):\n",
    "    model_infos = []\n",
    "    info = {\n",
    "            'model_name': None,\n",
    "            'model_params': None,\n",
    "            'train_set': None,\n",
    "            'test_set': None,\n",
    "            'training_losses': None,\n",
    "            'training_accuracies': None,\n",
    "            'test_loss': None,\n",
    "            'test_accuracy': None,\n",
    "            'train_attributions': None,\n",
    "            'test_attributions': None\n",
    "            }\n",
    "\n",
    "    if retrain:\n",
    "        X, Y = dataloader.process_data()\n",
    "        for i in range(0, NUM_ITER):\n",
    "            new_dir_name = '/iter_' + str(i)\n",
    "            create_new_dir(new_dir_name)\n",
    "\n",
    "            model_infos = init_model_infos(info, model_infos, SETS)\n",
    "\n",
    "            in_features = X.shape[1]\n",
    "            models = create_models(in_features)\n",
    "\n",
    "            subsets = utils.subsample(X, Y, SUBSAMPLE_SIZE, SETS)\n",
    "            model_infos = populate_train_test_sets(subsets, info, model_infos)\n",
    "\n",
    "            save_model_infos(model_infos, new_dir_name, i)\n",
    "\n",
    "            models_train_test = [(info['train_set'], info['test_set']) for info in model_infos]\n",
    "            dataloaders = dataloader.get_loaders(models_train_test, BATCH_SIZE)\n",
    "\n",
    "            model_infos = train_models(\n",
    "                    models,\n",
    "                    dataloaders,\n",
    "                    model_infos,\n",
    "                    log_tensorboard=True\n",
    "                    )\n",
    "            save_model_infos(model_infos, new_dir_name, i)\n",
    "\n",
    "            model_infos = test_models(models, dataloaders, model_infos)\n",
    "            save_model_infos(model_infos, new_dir_name, i)\n",
    "\n",
    "            model_infos = get_model_attributions(models, dataloaders, model_infos)\n",
    "            save_model_infos(model_infos, new_dir_name, i)\n",
    "\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e255a294",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a8e5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iter: 0, loss: 0.6957281827926636\n",
      "epoch: 0, iter: 150, loss: 0.6732441782951355\n",
      "epoch: 0, iter: 300, loss: 0.6870831251144409\n",
      "epoch: 0, iter: 450, loss: 0.7057802081108093\n",
      "epoch: 0, iter: 600, loss: 0.697930097579956\n",
      "epoch: 0, iter: 750, loss: 0.6910896897315979\n",
      "epoch: 0, iter: 900, loss: 0.6863833665847778\n",
      "epoch: 0, iter: 1050, loss: 0.6765116453170776\n",
      "epoch: 0, iter: 1200, loss: 0.7075406908988953\n",
      "epoch: 0, iter: 1350, loss: 0.6761417984962463\n",
      "epoch: 0, iter: 1500, loss: 0.6970409154891968\n",
      "Finish epoch 0, time elapsed 36.0098979473114\n",
      "epoch: 1, iter: 0, loss: 0.6841506361961365\n",
      "epoch: 1, iter: 150, loss: 0.6920298933982849\n",
      "epoch: 1, iter: 300, loss: 0.7068306803703308\n",
      "epoch: 1, iter: 450, loss: 0.6856793761253357\n",
      "epoch: 1, iter: 600, loss: 0.7275334000587463\n",
      "epoch: 1, iter: 750, loss: 0.7008898854255676\n",
      "epoch: 1, iter: 900, loss: 0.6827049255371094\n",
      "epoch: 1, iter: 1050, loss: 0.7009462118148804\n",
      "epoch: 1, iter: 1200, loss: 0.715234637260437\n",
      "epoch: 1, iter: 1350, loss: 0.7064211964607239\n",
      "epoch: 1, iter: 1500, loss: 0.7019533514976501\n",
      "Finish epoch 1, time elapsed 36.81954908370972\n",
      "epoch: 2, iter: 0, loss: 0.7028213739395142\n",
      "epoch: 2, iter: 150, loss: 0.6826142072677612\n",
      "epoch: 2, iter: 300, loss: 0.6660807132720947\n",
      "epoch: 2, iter: 450, loss: 0.6815652847290039\n",
      "epoch: 2, iter: 600, loss: 0.6888871192932129\n",
      "epoch: 2, iter: 750, loss: 0.6641779541969299\n",
      "epoch: 2, iter: 900, loss: 0.6972548961639404\n",
      "epoch: 2, iter: 1050, loss: 0.6873692870140076\n",
      "epoch: 2, iter: 1200, loss: 0.7021359801292419\n",
      "epoch: 2, iter: 1350, loss: 0.7126988768577576\n",
      "epoch: 2, iter: 1500, loss: 0.7025769948959351\n",
      "Finish epoch 2, time elapsed 36.8667151927948\n",
      "epoch: 3, iter: 0, loss: 0.6919423341751099\n",
      "epoch: 3, iter: 150, loss: 0.6933305263519287\n",
      "epoch: 3, iter: 300, loss: 0.6969510316848755\n",
      "epoch: 3, iter: 450, loss: 0.7003939151763916\n",
      "epoch: 3, iter: 600, loss: 0.6872906684875488\n",
      "epoch: 3, iter: 750, loss: 0.7062177658081055\n",
      "epoch: 3, iter: 900, loss: 0.6979259848594666\n",
      "epoch: 3, iter: 1050, loss: 0.6764912009239197\n",
      "epoch: 3, iter: 1200, loss: 0.6904494762420654\n",
      "epoch: 3, iter: 1350, loss: 0.697786271572113\n",
      "epoch: 3, iter: 1500, loss: 0.7016753554344177\n",
      "Finish epoch 3, time elapsed 38.79689908027649\n",
      "epoch: 4, iter: 0, loss: 0.7023327350616455\n",
      "epoch: 4, iter: 150, loss: 0.6984353065490723\n",
      "epoch: 4, iter: 300, loss: 0.6873197555541992\n",
      "epoch: 4, iter: 450, loss: 0.7078508138656616\n",
      "epoch: 4, iter: 600, loss: 0.7066181302070618\n",
      "epoch: 4, iter: 750, loss: 0.6938324570655823\n",
      "epoch: 4, iter: 900, loss: 0.6920208930969238\n",
      "epoch: 4, iter: 1050, loss: 0.6791145205497742\n",
      "epoch: 4, iter: 1200, loss: 0.6960616707801819\n",
      "epoch: 4, iter: 1350, loss: 0.6858454942703247\n",
      "epoch: 4, iter: 1500, loss: 0.6983436346054077\n",
      "Finish epoch 4, time elapsed 42.14789700508118\n",
      "epoch: 5, iter: 0, loss: 0.6932778358459473\n",
      "epoch: 5, iter: 150, loss: 0.6878257393836975\n",
      "epoch: 5, iter: 300, loss: 0.7030804753303528\n",
      "epoch: 5, iter: 450, loss: 0.7168555855751038\n",
      "epoch: 5, iter: 600, loss: 0.6954580545425415\n",
      "epoch: 5, iter: 750, loss: 0.6852724552154541\n",
      "epoch: 5, iter: 900, loss: 0.6830167770385742\n",
      "epoch: 5, iter: 1050, loss: 0.7052704691886902\n",
      "epoch: 5, iter: 1200, loss: 0.6746774911880493\n",
      "epoch: 5, iter: 1350, loss: 0.7062626481056213\n",
      "epoch: 5, iter: 1500, loss: 0.691381573677063\n",
      "Finish epoch 5, time elapsed 42.623709201812744\n",
      "epoch: 6, iter: 0, loss: 0.6938431859016418\n",
      "epoch: 6, iter: 150, loss: 0.702154815196991\n",
      "epoch: 6, iter: 300, loss: 0.6818079352378845\n",
      "epoch: 6, iter: 450, loss: 0.6796348690986633\n",
      "epoch: 6, iter: 600, loss: 0.7092375755310059\n",
      "epoch: 6, iter: 750, loss: 0.6957666277885437\n",
      "epoch: 6, iter: 900, loss: 0.6838197112083435\n",
      "epoch: 6, iter: 1050, loss: 0.70841383934021\n",
      "epoch: 6, iter: 1200, loss: 0.7064306735992432\n",
      "epoch: 6, iter: 1350, loss: 0.6937295198440552\n",
      "epoch: 6, iter: 1500, loss: 0.699639081954956\n",
      "Finish epoch 6, time elapsed 43.01708626747131\n",
      "epoch: 7, iter: 0, loss: 0.6740209460258484\n",
      "epoch: 7, iter: 150, loss: 0.6928772330284119\n",
      "epoch: 7, iter: 300, loss: 0.699427604675293\n",
      "epoch: 7, iter: 450, loss: 0.6964340806007385\n",
      "epoch: 7, iter: 600, loss: 0.6906160116195679\n",
      "epoch: 7, iter: 750, loss: 0.6768775582313538\n",
      "epoch: 7, iter: 900, loss: 0.6945255994796753\n",
      "epoch: 7, iter: 1050, loss: 0.7021912932395935\n",
      "epoch: 7, iter: 1200, loss: 0.7054117321968079\n",
      "epoch: 7, iter: 1350, loss: 0.6851028800010681\n",
      "epoch: 7, iter: 1500, loss: 0.6774512529373169\n",
      "Finish epoch 7, time elapsed 42.445127964019775\n",
      "epoch: 8, iter: 0, loss: 0.6777763366699219\n",
      "epoch: 8, iter: 150, loss: 0.6881152987480164\n",
      "epoch: 8, iter: 300, loss: 0.6767781972885132\n",
      "epoch: 8, iter: 450, loss: 0.6869409680366516\n",
      "epoch: 8, iter: 600, loss: 0.6975980997085571\n",
      "epoch: 8, iter: 750, loss: 0.6836634278297424\n",
      "epoch: 8, iter: 900, loss: 0.6943967938423157\n",
      "epoch: 8, iter: 1050, loss: 0.6874984502792358\n",
      "epoch: 8, iter: 1200, loss: 0.7092803120613098\n",
      "epoch: 8, iter: 1350, loss: 0.6664243936538696\n",
      "epoch: 8, iter: 1500, loss: 0.6923364400863647\n",
      "Finish epoch 8, time elapsed 55.31411004066467\n",
      "epoch: 9, iter: 0, loss: 0.6912802457809448\n",
      "epoch: 9, iter: 150, loss: 0.6907008290290833\n",
      "epoch: 9, iter: 300, loss: 0.6835795044898987\n",
      "epoch: 9, iter: 450, loss: 0.7040801048278809\n",
      "epoch: 9, iter: 600, loss: 0.6813770532608032\n",
      "epoch: 9, iter: 750, loss: 0.6981421113014221\n",
      "epoch: 9, iter: 900, loss: 0.6905304193496704\n",
      "epoch: 9, iter: 1050, loss: 0.687895655632019\n",
      "epoch: 9, iter: 1200, loss: 0.7022628784179688\n",
      "epoch: 9, iter: 1350, loss: 0.6719609498977661\n",
      "epoch: 9, iter: 1500, loss: 0.6887531876564026\n",
      "Finish epoch 9, time elapsed 358.51465129852295\n",
      "epoch: 10, iter: 0, loss: 0.7281265258789062\n",
      "epoch: 10, iter: 150, loss: 0.6677800416946411\n",
      "epoch: 10, iter: 300, loss: 0.693732738494873\n",
      "epoch: 10, iter: 450, loss: 0.6900773048400879\n",
      "epoch: 10, iter: 600, loss: 0.6974436044692993\n",
      "epoch: 10, iter: 750, loss: 0.6941755414009094\n",
      "epoch: 10, iter: 900, loss: 0.6818633675575256\n",
      "epoch: 10, iter: 1050, loss: 0.6973951458930969\n",
      "epoch: 10, iter: 1200, loss: 0.6754980087280273\n",
      "epoch: 10, iter: 1350, loss: 0.7063238024711609\n",
      "epoch: 10, iter: 1500, loss: 0.6986913681030273\n",
      "Finish epoch 10, time elapsed 153.29938983917236\n",
      "epoch: 11, iter: 0, loss: 0.6729347705841064\n",
      "epoch: 11, iter: 150, loss: 0.7177316546440125\n",
      "epoch: 11, iter: 300, loss: 0.6948459148406982\n",
      "epoch: 11, iter: 450, loss: 0.711337685585022\n",
      "epoch: 11, iter: 600, loss: 0.6994778513908386\n",
      "epoch: 11, iter: 750, loss: 0.6954399347305298\n",
      "epoch: 11, iter: 900, loss: 0.6837835311889648\n",
      "epoch: 11, iter: 1050, loss: 0.696320652961731\n",
      "epoch: 11, iter: 1200, loss: 0.6876455545425415\n",
      "epoch: 11, iter: 1350, loss: 0.6781202554702759\n",
      "epoch: 11, iter: 1500, loss: 0.7183703184127808\n",
      "Finish epoch 11, time elapsed 357.02225708961487\n",
      "epoch: 12, iter: 0, loss: 0.7230650782585144\n",
      "epoch: 12, iter: 150, loss: 0.702585756778717\n",
      "epoch: 12, iter: 300, loss: 0.6771116256713867\n",
      "epoch: 12, iter: 450, loss: 0.6905831098556519\n",
      "epoch: 12, iter: 600, loss: 0.6712578535079956\n",
      "epoch: 12, iter: 750, loss: 0.6983234286308289\n",
      "epoch: 12, iter: 900, loss: 0.6975029110908508\n",
      "epoch: 12, iter: 1050, loss: 0.6947469711303711\n",
      "epoch: 12, iter: 1200, loss: 0.7062260508537292\n",
      "epoch: 12, iter: 1350, loss: 0.6825191974639893\n",
      "epoch: 12, iter: 1500, loss: 0.6917250156402588\n",
      "Finish epoch 12, time elapsed 210.66313815116882\n",
      "epoch: 13, iter: 0, loss: 0.6849675178527832\n",
      "epoch: 13, iter: 150, loss: 0.6752132177352905\n",
      "epoch: 13, iter: 300, loss: 0.6846151351928711\n",
      "epoch: 13, iter: 450, loss: 0.6926930546760559\n",
      "epoch: 13, iter: 600, loss: 0.6894367337226868\n",
      "epoch: 13, iter: 750, loss: 0.697827160358429\n",
      "epoch: 13, iter: 900, loss: 0.6826232671737671\n",
      "epoch: 13, iter: 1050, loss: 0.6909677386283875\n",
      "epoch: 13, iter: 1200, loss: 0.6936579942703247\n",
      "epoch: 13, iter: 1350, loss: 0.6813735961914062\n",
      "epoch: 13, iter: 1500, loss: 0.6794278621673584\n",
      "Finish epoch 13, time elapsed 320.41910219192505\n",
      "epoch: 14, iter: 0, loss: 0.724151074886322\n",
      "epoch: 14, iter: 150, loss: 0.6877794861793518\n",
      "epoch: 14, iter: 300, loss: 0.7009671926498413\n",
      "epoch: 14, iter: 450, loss: 0.6759452223777771\n",
      "epoch: 14, iter: 600, loss: 0.680851936340332\n",
      "epoch: 14, iter: 750, loss: 0.6906089186668396\n",
      "epoch: 14, iter: 900, loss: 0.6934564709663391\n",
      "epoch: 14, iter: 1050, loss: 0.6974798440933228\n",
      "epoch: 14, iter: 1200, loss: 0.6715432405471802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14, iter: 1350, loss: 0.680939793586731\n",
      "epoch: 14, iter: 1500, loss: 0.676382303237915\n",
      "Finish epoch 14, time elapsed 297.3283669948578\n",
      "epoch: 15, iter: 0, loss: 0.6586213707923889\n",
      "epoch: 15, iter: 150, loss: 0.6989959478378296\n",
      "epoch: 15, iter: 300, loss: 0.6864619851112366\n",
      "epoch: 15, iter: 450, loss: 0.7065724730491638\n",
      "epoch: 15, iter: 600, loss: 0.6970138549804688\n",
      "epoch: 15, iter: 750, loss: 0.6940413117408752\n",
      "epoch: 15, iter: 900, loss: 0.6928299069404602\n",
      "epoch: 15, iter: 1050, loss: 0.6836569309234619\n",
      "epoch: 15, iter: 1200, loss: 0.6891104578971863\n",
      "epoch: 15, iter: 1350, loss: 0.7027093172073364\n",
      "epoch: 15, iter: 1500, loss: 0.6946178674697876\n",
      "Finish epoch 15, time elapsed 365.11209654808044\n",
      "epoch: 16, iter: 0, loss: 0.7036877870559692\n",
      "epoch: 16, iter: 150, loss: 0.6688421964645386\n",
      "epoch: 16, iter: 300, loss: 0.7361324429512024\n",
      "epoch: 16, iter: 450, loss: 0.6726380586624146\n",
      "epoch: 16, iter: 600, loss: 0.6796327829360962\n",
      "epoch: 16, iter: 750, loss: 0.7070803046226501\n",
      "epoch: 16, iter: 900, loss: 0.6729543805122375\n",
      "epoch: 16, iter: 1050, loss: 0.6860024929046631\n",
      "epoch: 16, iter: 1200, loss: 0.700513482093811\n"
     ]
    }
   ],
   "source": [
    "X, Y = dataloader.process_data()\n",
    "in_features = X.shape[1]\n",
    "save_model_fn = lambda model_infos: save_model_infos(model_infos, '/iter_0', 0)\n",
    "model_infos = attack.run(0, in_features, save_model_fn)\n",
    "save_model_infos(model_infos, '/iter_0', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80a5529",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, NUM_ITER):\n",
    "    iter_dir = '/iter_' + str(i)\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "\n",
    "    for j in range(0, 4):\n",
    "        path = EXPERIMENT_DIR + iter_dir + '/model_' + str(j) + '.npy'\n",
    "        model_info = np.load(path, allow_pickle=True)\n",
    "\n",
    "        losses = model_info.item().get('training_losses')\n",
    "        accu = model_info.item().get('training_accuracies')\n",
    "\n",
    "        train_losses.append(losses)\n",
    "        train_accuracies.append(accu)\n",
    "\n",
    "    plt_dir = iter_dir + '/plots'\n",
    "    create_new_dir(plt_dir)\n",
    "    utils.plot_losses(train_losses, EXPERIMENT_DIR + plt_dir)\n",
    "    utils.plot_accuracies(train_accuracies, EXPERIMENT_DIR + plt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c08388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Loss/ Accuracies\")\n",
    "for i in range(0, NUM_ITER):\n",
    "    iter_dir = '/iter_' + str(i)\n",
    "    test_losses = []\n",
    "    test_acc = []\n",
    "\n",
    "    for j in range(0, 4):\n",
    "        path = EXPERIMENT_DIR + iter_dir + '/model_' + str(j) + '.npy'\n",
    "        model_info = np.load(path, allow_pickle=True)\n",
    "        losses = model_info.item().get('test_loss')\n",
    "        acc = model_info.item().get('test_accuracy')\n",
    "        test_losses.append(np.array([losses])[0])\n",
    "        test_acc.append(np.array([acc])[0])\n",
    "\n",
    "print(f'Losses {test_losses}')\n",
    "print(f'Accuracies {test_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
